{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz8sDmKYhX9i",
        "outputId": "b049d2ef-eb4b-457b-f275-84e0ce83f937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok scikit-learn requests nest-asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTtrmhvjWKPA",
        "outputId": "522d6753-6321-4d0f-b4cf-7d9b97bbaafc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.51.0)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow<22,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.12.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.29.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofFnOchmgnhA",
        "outputId": "5fcc9c40-7de1-446d-efba-10d58f715667"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import time\n",
        "import requests\n",
        "import asyncio\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "import nest_asyncio\n",
        "import os\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Apply the asyncio patch\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# --- 1. Retrieval Model (using scikit-learn) ---\n",
        "class VectorRetriever:\n",
        "    \"\"\"Handles the \"Retrieval\" part of RAG using TF-IDF.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        self.document_chunks = []\n",
        "        self.chunk_vectors = None\n",
        "\n",
        "    def fit(self, document_chunks: list[str]):\n",
        "        self.document_chunks = document_chunks\n",
        "        self.chunk_vectors = self.vectorizer.fit_transform(document_chunks)\n",
        "\n",
        "    def retrieve(self, query: str, top_k: int = 3) -> list[str]:\n",
        "        if self.chunk_vectors is None: return []\n",
        "        query_vector = self.vectorizer.transform([query])\n",
        "        similarities = cosine_similarity(query_vector, self.chunk_vectors).flatten()\n",
        "        if np.max(similarities) < 0.1: return []\n",
        "        top_k_indices = similarities.argsort()[-top_k:][::-1]\n",
        "        return [self.document_chunks[i] for i in top_k_indices if similarities[i] > 0.1]\n",
        "\n",
        "# --- 2. LLM Generation (using Gemini API) ---\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class LLMClient:\n",
        "    \"\"\"Client for interacting with the Gemini Large Language Model API.\"\"\"\n",
        "    def __init__(self, model_name=\"gemini-2.5-flash-preview-09-2025\"):\n",
        "        self.api_key = os.environ.get('GEMINI_API_KEY')\n",
        "        if not self.api_key:\n",
        "            logging.error(\"ERROR: 'GEMINI_API_KEY' environment variable not found.\")\n",
        "\n",
        "        self.api_url = f\"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={self.api_key}\"\n",
        "        self.session = requests.Session()\n",
        "\n",
        "    async def generate_text(self, prompt: str, max_retries: int = 5) -> str:\n",
        "        \"\"\"Calls the Gemini API (non-blocking).\"\"\"\n",
        "        if not self.api_key:\n",
        "            return \"Error: API Key is missing. Please set the GEMINI_API_KEY environment variable.\"\n",
        "\n",
        "        payload = {\n",
        "            # FIX: Removed the escaped quotes that caused a SyntaxError in previous attempts\n",
        "            \"contents\": [{\"parts\": [{\"text\": prompt}]}],\n",
        "            \"tools\": [{\"google_search\": {}}],\n",
        "            \"systemInstruction\": {\n",
        "                \"parts\": [{\n",
        "                    \"text\": (\"You are a helpful and knowledgeable financial advisor. \"\n",
        "                             \"Follow the user's instructions in the prompt. \"\n",
        "                             \"If you use your search tool for public information, \"\n",
        "                             \"try to cite your sources or mention where the information is from.\")\n",
        "                }]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        headers = {'Content-Type': 'application/json'}\n",
        "        delay = 1\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                response = await asyncio.to_thread(\n",
        "                    self.session.post,\n",
        "                    self.api_url,\n",
        "                    headers=headers,\n",
        "                    json=payload,\n",
        "                    timeout=90\n",
        "                )\n",
        "                if response.status_code == 200:\n",
        "                    result = response.json()\n",
        "                    candidate = result.get('candidates', [{}])[0]\n",
        "                    text_part = candidate.get('content', {}).get('parts', [{}])[0].get('text', None)\n",
        "                    return text_part if text_part else \"Error: Could not parse response.\"\n",
        "                elif response.status_code in (429, 500, 503):\n",
        "                    logging.warning(f\"API Error: Status {response.status_code}. Retrying in {delay}s...\")\n",
        "                    await asyncio.sleep(delay)\n",
        "                    delay *= 2\n",
        "                else:\n",
        "                    logging.error(f\"API Error: Status {response.status_code} - {response.text}\")\n",
        "                    return f\"Error: API request failed with status {response.status_code}.\"\n",
        "            except (requests.exceptions.RequestException, asyncio.TimeoutError) as e:\n",
        "                logging.error(f\"Network Error: {e}. Retrying in {delay}s...\")\n",
        "                await asyncio.sleep(delay)\n",
        "                delay *= 2\n",
        "\n",
        "        return \"Error: Model failed to generate a response after several retries.\"\n",
        "\n",
        "\n",
        "# --- 3. RAG Orchestration (RAGChatbot) ---\n",
        "class RAGChatbot:\n",
        "    \"\"\"Orchestrates the entire RAG pipeline.\"\"\"\n",
        "    def __init__(self, retriever: VectorRetriever, llm_client: LLMClient):\n",
        "        self.retriever = retriever\n",
        "        self.llm_client = llm_client\n",
        "\n",
        "    def _build_prompt(self, query: str, context_chunks: list[str]) -> str:\n",
        "        \"\"\"Builds the hybrid prompt for the LLM.\"\"\"\n",
        "        if not context_chunks:\n",
        "            return f\"\"\"\n",
        "            **Question:** {query}\n",
        "            **Instruction:** Please answer the user's question. Use your search tool to find the\n",
        "            most current and relevant public information.\n",
        "            \"\"\"\n",
        "\n",
        "        context = \"\\\\n\\\\n\".join(f\"[Document Chunk {i+1}]:\\\\n{chunk}\" for i, chunk in enumerate(context_chunks))\n",
        "\n",
        "        return f\"\"\"\n",
        "        **Context from internal documents:**\n",
        "        {context}\n",
        "\n",
        "        **Question:** {query}\n",
        "\n",
        "        **Instruction:** You are a financial analyst.\n",
        "        1. First, check the \"Context from internal documents\". If it answers the question, use it.\n",
        "        2. If the context does not answer, use your Google Search tool for a public answer.\n",
        "        \"\"\"\n",
        "\n",
        "    async def ask(self, query: str) -> dict:\n",
        "        \"\"\"Main method to run the full RAG pipeline.\"\"\"\n",
        "        retrieved_chunks = self.retriever.retrieve(query, top_k=3)\n",
        "        prompt = self._build_prompt(query, retrieved_chunks)\n",
        "        answer = await self.llm_client.generate_text(prompt.strip())\n",
        "        return {\"query\": query, \"answer\": answer}\n",
        "\n",
        "# --- 4. Knowledge Base ---\n",
        "FINANCIAL_DOCUMENTS = [\n",
        "    \"[Q2 2025 Report, Page 5]: Revenue for the second quarter was $150 million, a 10% increase year-over-year from $136.4 million in Q2 2024.\",\n",
        "    \"[Q2 2025 Report, Page 6]: Cost of Goods Sold (COGS) for Q2 2025 was $60 million, representing 40% of revenue.\",\n",
        "    \"[Q2 2025 Earnings Call, Page 2]: The increase in COGS as a percentage of revenue was primarily driven by higher raw material costs and increased shipping logistics expenses.\",\n",
        "    \"[QG2 2025 Report, Page 7]: Research and Development (R&D) expenses were $25 million, compared to $22 million in Q2 2024.\",\n",
        "    \"[Q2 2024 Report, Page 5]: Revenue for the second quarter of 2024 was $136.4 million. R&D expenses were $22 million for the same period.\",\n",
        "    \"[Company Strategy Memo, Page 1]: Our primary focus for 2025 is expanding our market share in Europe and investing in R&D.\"\n",
        "]\n",
        "\n",
        "# --- 5. Streamlit UI Functions (Updated) ---\n",
        "\n",
        "def apply_custom_css():\n",
        "    \"\"\"Applies the maroon and white theme and professionalizes the UI.\"\"\"\n",
        "    # Maroon color: #800000\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "        <style>\n",
        "        /* Main Theme */\n",
        "        .stApp {\n",
        "            background-color: white; /* Overall background */\n",
        "        }\n",
        "\n",
        "        /* Sidebar background */\n",
        "        /* Targets the main sidebar container */\n",
        "        [data-testid=\"stSidebar\"] {\n",
        "            background-color: #800000 !important; /* Maroon Sidebar */\n",
        "            color: white;\n",
        "            border-right: 5px solid #660000; /* Darker maroon border for professional look */\n",
        "        }\n",
        "\n",
        "        /* Sidebar text and headers */\n",
        "        [data-testid=\"stSidebar\"] p, [data-testid=\"stSidebar\"] h2, [data-testid=\"stSidebar\"] h3 {\n",
        "            color: white !important;\n",
        "        }\n",
        "\n",
        "        /* Main Title visibility and centering */\n",
        "        /* Targets the title container */\n",
        "        div[data-testid=\"stVerticalBlock\"] h1 {\n",
        "            color: #333333 !important; /* Dark gray/black for visibility */\n",
        "            text-align: center;\n",
        "            font-size: 2.5em;\n",
        "            padding-top: 20px;\n",
        "        }\n",
        "\n",
        "        /* Centering the Chatbot (main column) */\n",
        "        .block-container {\n",
        "            padding-top: 2rem;\n",
        "            padding-bottom: 2rem;\n",
        "            max-width: 900px !important; /* Limit width for centering effect */\n",
        "            margin-left: auto;\n",
        "            margin-right: auto;\n",
        "        }\n",
        "\n",
        "        /* Chat Messages */\n",
        "        .stChatMessage [data-testid=\"stChatMessageContent\"] {\n",
        "            border-radius: 15px;\n",
        "            padding: 10px 15px;\n",
        "            box-shadow: 1px 1px 5px rgba(0,0,0,0.1);\n",
        "        }\n",
        "\n",
        "        /* User message bubble (White on Maroon background) */\n",
        "        .stChatMessage:nth-child(odd) [data-testid=\"stChatMessageContent\"] {\n",
        "            background-color: #800000;\n",
        "            color: white;\n",
        "            border-bottom-right-radius: 0;\n",
        "        }\n",
        "\n",
        "        /* Assistant message bubble (Dark Maroon text on Light background) */\n",
        "        .stChatMessage:nth-child(even) [data-testid=\"stChatMessageContent\"] {\n",
        "            background-color: #f0f2f6; /* Light gray */\n",
        "            color: #400000; /* Dark Maroon text */\n",
        "            border-bottom-left-radius: 0;\n",
        "        }\n",
        "\n",
        "        /* Stock Marquee CSS */\n",
        "        @keyframes marquee {\n",
        "            0%   { transform: translate(100%, 0); }\n",
        "            100% { transform: translate(-100%, 0); }\n",
        "        }\n",
        "        .marquee-container {\n",
        "            width: 100%;\n",
        "            overflow: hidden;\n",
        "            background-color: #333333; /* Darker background for ticker */\n",
        "            color: white; /* White text */\n",
        "            padding: 5px 0;\n",
        "            position: fixed;\n",
        "            top: 0;\n",
        "            left: 0;\n",
        "            z-index: 2000; /* High z-index to stay on top */\n",
        "            box-shadow: 0 2px 5px rgba(0,0,0,0.2);\n",
        "        }\n",
        "        .marquee-content {\n",
        "            display: inline-block;\n",
        "            white-space: nowrap;\n",
        "            animation: marquee 40s linear infinite;\n",
        "            font-weight: bold;\n",
        "            font-size: 1.1em;\n",
        "            padding-left: 100%;\n",
        "        }\n",
        "        .stock-up { color: #00e676; } /* Green for up */\n",
        "        .stock-down { color: #e53935; } /* Red for down */\n",
        "\n",
        "        /* Push the main content down because of the fixed marquee */\n",
        "        /* Adjusted margin-top to account for the marquee height (approx 40px) */\n",
        "        div.stApp > header {\n",
        "            position: relative;\n",
        "            z-index: 100;\n",
        "            background: none;\n",
        "        }\n",
        "\n",
        "        /* Use padding on the main block to push content below the fixed marquee */\n",
        "        .stApp > div:first-child > div:first-child {\n",
        "            padding-top: 45px;\n",
        "        }\n",
        "\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "def stock_marquee():\n",
        "    \"\"\"Displays a professional stock ticker marquee.\"\"\"\n",
        "    # Simulated Stock Data (in a real app, this would be fetched from an API)\n",
        "    stocks = [\n",
        "        (\"AAPL (Equity)\", 195.25, \"+0.89\", True),\n",
        "        (\"MSFT (Equity)\", 412.60, \"-1.15\", False),\n",
        "        (\"GOOGL (Equity)\", 175.45, \"+2.01\", True),\n",
        "        (\"TSLA (Equity)\", 205.10, \"-3.50\", False),\n",
        "        (\"S&P 500 (Index)\", 5200.70, \"+12.15\", True),\n",
        "        (\"USD/INR (FX)\", 83.50, \"-0.05\", False),\n",
        "    ]\n",
        "\n",
        "    marquee_content = \"\"\n",
        "    for ticker, price, change, is_up in stocks:\n",
        "        color_class = \"stock-up\" if is_up else \"stock-down\"\n",
        "        sign = \"â–²\" if is_up else \"â–¼\" # Triangle indicator\n",
        "        marquee_content += (\n",
        "            f\"<span style='padding-right: 70px; display: inline-block;'> \"\n",
        "            f\"**{ticker}:** &nbsp; ${price} &nbsp; <span class='{color_class}'>{sign} {change}</span>\"\n",
        "            f\"</span>\"\n",
        "        )\n",
        "\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <div class=\"marquee-container\">\n",
        "            <div class=\"marquee-content\">\n",
        "                {marquee_content * 5} </div>\n",
        "        </div>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "def sidebar_updates():\n",
        "    \"\"\"Shows the latest news and weather updates in a professional sidebar.\"\"\"\n",
        "    st.sidebar.markdown(\n",
        "        \"\"\"\n",
        "        <style>\n",
        "            /* Specific professional styling for sidebar content */\n",
        "            [data-testid=\"stSidebar\"] .stMarkdown h3 {\n",
        "                border-bottom: 2px solid white;\n",
        "                padding-bottom: 5px;\n",
        "                margin-top: 20px;\n",
        "            }\n",
        "            [data-testid=\"stSidebar\"] li {\n",
        "                margin-bottom: 8px;\n",
        "            }\n",
        "        </style>\n",
        "        \"\"\", unsafe_allow_html=True\n",
        "    )\n",
        "\n",
        "    st.sidebar.title(\"ðŸ“ˆ Market & Global Intelligence\")\n",
        "    st.sidebar.markdown(\"---\")\n",
        "\n",
        "    # National & International News (Simulated)\n",
        "    st.sidebar.subheader(\"ðŸŒ National & Global News\")\n",
        "    st.sidebar.markdown(\n",
        "        \"\"\"\n",
        "        * **Global Markets:** European stocks rise on strong tech earnings, fueling investor confidence in the sector.\n",
        "        * **India:** Parliament debates new financial reform bill aimed at streamlining cross-border investments.\n",
        "        * **Tech:** Major AI company announces breakthrough in chip design, potentially reducing computation costs by 30%.\n",
        "        \"\"\"\n",
        "    )\n",
        "    st.sidebar.markdown(\"---\")\n",
        "\n",
        "    # Sports Highlights (kept brief and professional)\n",
        "    st.sidebar.subheader(\"âš½ Sports Highlights (Sentiment)\")\n",
        "    st.sidebar.markdown(\n",
        "        \"\"\"\n",
        "        * **Cricket:** India wins series decider by 5 wickets, boosting national morale and advertising revenue forecasts.\n",
        "        * **Football:** Local club advances to national cup semi-finals, driving up local spending forecasts.\n",
        "        \"\"\"\n",
        "    )\n",
        "    st.sidebar.markdown(\"---\")\n",
        "\n",
        "    # Weather Updates (Impact on logistics/commodities)\n",
        "    st.sidebar.subheader(\"â˜€ï¸ Regional Logistics Update\")\n",
        "    st.sidebar.markdown(\n",
        "        \"\"\"\n",
        "        * **Mumbai:** 28Â°C, Partly Cloudy. No major disruption to port operations expected.\n",
        "        * **New York:** 12Â°C, Chance of Rain. Potential minor delays in road freight logistics.\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "# --- 6. Main Application Logic ---\n",
        "\n",
        "@st.cache_resource\n",
        "def load_bot():\n",
        "    \"\"\"Loads and initializes the bot. Cached to run only once.\"\"\"\n",
        "    logging.info(\"Initializing chatbot components...\")\n",
        "    try:\n",
        "        retriever = VectorRetriever()\n",
        "        llm_client = LLMClient()\n",
        "        if not llm_client.api_key:\n",
        "             logging.error(\"GEMINI_API_KEY not found. Bot will not function.\")\n",
        "             return None\n",
        "        retriever.fit(FINANCIAL_DOCUMENTS)\n",
        "        bot = RAGChatbot(retriever, llm_client)\n",
        "        logging.info(\"Chatbot is ready!\")\n",
        "        return bot\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading bot: {e}\")\n",
        "        st.error(f\"Error loading bot: {e}. Is your GEMINI_API_KEY set?\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    st.set_page_config(\n",
        "        page_title=\"Financial Advisor\",\n",
        "        page_icon=\"ðŸ“ˆ\", # Changed icon\n",
        "        layout=\"wide\"\n",
        "    )\n",
        "\n",
        "    # --- 1. Apply Custom UI ---\n",
        "    apply_custom_css()\n",
        "    stock_marquee()\n",
        "    sidebar_updates()\n",
        "\n",
        "    # --- 2. Main Chatbot Interface ---\n",
        "\n",
        "    # The title is now visible due to CSS changes\n",
        "    st.title(\"ðŸ¤– Hybrid Financial Advisor Chatbot\")\n",
        "    st.caption(\"A RAG-powered analyst for internal documents and real-time data.\")\n",
        "\n",
        "    bot = load_bot()\n",
        "    if not bot:\n",
        "        # st.error is now handled inside load_bot for API key issues\n",
        "        return\n",
        "\n",
        "    # Initialize chat history\n",
        "    if \"messages\" not in st.session_state:\n",
        "        st.session_state.messages = [{\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": \"Hello! I am your Hybrid Financial Advisor. What can I analyze for you today?\"\n",
        "        }]\n",
        "\n",
        "    # Display past messages\n",
        "    for message in st.session_state.messages:\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "    # Get new user input\n",
        "    if prompt := st.chat_input(\"What is your question?\"):\n",
        "        # Add user message to history and display it\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(prompt)\n",
        "\n",
        "        # Get bot response\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            with st.spinner(\"Analyzing data and generating report...\"):\n",
        "                response_dict = asyncio.run(bot.ask(prompt))\n",
        "                response = response_dict['answer']\n",
        "                st.markdown(response)\n",
        "\n",
        "        # Add bot response to history\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok, conf\n",
        "from google.colab import userdata\n",
        "import threading\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Kill any old Streamlit processes\n",
        "!killall streamlit\n",
        "\n",
        "# --- 1. Get Authtoken for NGROK ---\n",
        "authtoken = userdata.get('NGROK_AUTHTOKEN')\n",
        "\n",
        "# --- 2. NEW: Get API Key for GEMINI ---\n",
        "gemini_key = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "if not authtoken:\n",
        "    print(\"=\"*50)\n",
        "    print(\"ðŸš¨ ERROR: NGROK_AUTHTOKEN not found in Colab secrets!\")\n",
        "    print(\"Please add your ngrok authtoken to secrets.\")\n",
        "    print(\"=\"*50)\n",
        "elif not gemini_key:\n",
        "    print(\"=\"*50)\n",
        "    print(\"ðŸš¨ ERROR: GEMINI_API_KEY not found in Colab secrets!\")\n",
        "    print(\"Please add your Gemini API key to secrets.\")\n",
        "    print(\"=\"*50)\n",
        "else:\n",
        "    # --- All keys found, proceed ---\n",
        "    conf.get_default().auth_token = authtoken\n",
        "\n",
        "    # Function to run streamlit in a new thread\n",
        "    def run_streamlit():\n",
        "        # --- NEW: Export the key before running streamlit ---\n",
        "        os.system(f'export GEMINI_API_KEY=\"{gemini_key}\" && streamlit run app.py')\n",
        "\n",
        "    # Start streamlit in a new thread\n",
        "    thread = threading.Thread(target=run_streamlit)\n",
        "    thread.start()\n",
        "\n",
        "    # Wait a few seconds for the server to start\n",
        "    time.sleep(5)\n",
        "\n",
        "    # Connect pyngrok to the streamlit port (8501)\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(\"=\"*50)\n",
        "    print(f\"ðŸš€ Your Streamlit app is live! Click the link below:\")\n",
        "    print(public_url)\n",
        "    print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKDYtNlJWOw9",
        "outputId": "0d7d212e-735a-4821-a908-19a6d78ca0a7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "ðŸš€ Your Streamlit app is live! Click the link below:\n",
            "NgrokTunnel: \"https://brevirostrate-suety-eduardo.ngrok-free.dev\" -> \"http://localhost:8501\"\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# --- 1. The VectorRetriever Class (from our app) ---\n",
        "class VectorRetriever:\n",
        "    \"\"\"Handles the \"Retrieval\" part of RAG using TF-IDF.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.vectorizer = TfidfVectorizer(stop_words='english')\n",
        "        self.document_chunks = []\n",
        "        self.chunk_vectors = None\n",
        "\n",
        "    def fit(self, document_chunks: list[str]):\n",
        "        self.document_chunks = document_chunks\n",
        "        self.chunk_vectors = self.vectorizer.fit_transform(document_chunks)\n",
        "\n",
        "    def retrieve(self, query: str, top_k: int = 3) -> list[str]:\n",
        "        if self.chunk_vectors is None: return []\n",
        "        query_vector = self.vectorizer.transform([query])\n",
        "        similarities = cosine_similarity(query_vector, self.chunk_vectors).flatten()\n",
        "        # We set a minimal threshold to avoid completely irrelevant matches\n",
        "        if np.max(similarities) < 0.1:\n",
        "            return []\n",
        "        top_k_indices = similarities.argsort()[-top_k:][::-1]\n",
        "        # Only return chunks that meet the threshold\n",
        "        return [self.document_chunks[i] for i in top_k_indices if similarities[i] > 0.1]\n",
        "\n",
        "# --- 2. The Knowledge Base (from our app) ---\n",
        "FINANCIAL_DOCUMENTS = [\n",
        "    \"[Q2 2025 Report, Page 5]: Revenue for the second quarter was $150 million, a 10% increase year-over-year from $136.4 million in Q2 2024.\",\n",
        "    \"[Q2 2025 Report, Page 6]: Cost of Goods Sold (COGS) for Q2 2025 was $60 million, representing 40% of revenue.\",\n",
        "    \"[Q2 2025 Earnings Call, Page 2]: The increase in COGS as a percentage of revenue was primarily driven by higher raw material costs and increased shipping logistics expenses.\",\n",
        "    \"[QG2 2025 Report, Page 7]: Research and Development (R&D) expenses were $25 million, compared to $22 million in Q2 2024.\",\n",
        "    \"[Q2 2024 Report, Page 5]: Revenue for the second quarter of 2024 was $136.4 million. R&D expenses were $22 million for the same period.\",\n",
        "    \"[Company Strategy Memo, Page 1]: Our primary focus for 2025 is expanding our market share in Europe and investing in R&D.\"\n",
        "]\n",
        "\n",
        "# --- 3. The Labeled Test Set ---\n",
        "# This is our ground truth. We manually map queries to the correct document(s).\n",
        "TEST_SET = [\n",
        "    {\n",
        "        \"query\": \"What was the revenue in Q2 2025?\",\n",
        "        \"relevant_docs\": [FINANCIAL_DOCUMENTS[0]]\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"Why did Cost of Goods Sold go up?\",\n",
        "        \"relevant_docs\": [FINANCIAL_DOCUMENTS[2]]\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"How much was spent on R&D in Q2 2025?\",\n",
        "        \"relevant_docs\": [FINANCIAL_DOCUMENTS[3]]\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What was R&D spending in 2024?\",\n",
        "        \"relevant_docs\": [FINANCIAL_DOCUMENTS[4]]\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What is the company's main strategy?\",\n",
        "        \"relevant_docs\": [FINANCIAL_DOCUMENTS[5]]\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What was the Q2 2025 COGS?\",\n",
        "        \"relevant_docs\": [FINANCIAL_DOCUMENTS[1]]\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What was the revenue in Q1 2025?\", # Answer is not in documents\n",
        "        \"relevant_docs\": []\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What are the company's goals and how much did they spend on R&D?\", # Multiple docs\n",
        "        \"relevant_docs\": [FINANCIAL_DOCUMENTS[3], FINANCIAL_DOCUMENTS[5]]\n",
        "    }\n",
        "]\n",
        "\n",
        "# --- 4. The Evaluation Function ---\n",
        "def evaluate_retriever(retriever: VectorRetriever, test_set: list, k: int = 3) -> dict:\n",
        "    \"\"\"\n",
        "    Calculates Precision@k and Recall@k for the retriever over the test set.\n",
        "    \"\"\"\n",
        "    precision_scores = []\n",
        "    recall_scores = []\n",
        "\n",
        "    for item in test_set:\n",
        "        query = item['query']\n",
        "        true_relevant_docs = set(item['relevant_docs'])\n",
        "        retrieved_chunks = set(retriever.retrieve(query, top_k=k))\n",
        "\n",
        "        # Handle the case where no documents should be retrieved (e.g., irrelevant query)\n",
        "        if not true_relevant_docs:\n",
        "            if not retrieved_chunks:\n",
        "                precision_scores.append(1.0)\n",
        "                recall_scores.append(1.0)\n",
        "            else:\n",
        "                precision_scores.append(0.0) # Retrieved irrelevant docs\n",
        "                recall_scores.append(0.0) # This case is technically undefined, but 0 is appropriate\n",
        "            continue\n",
        "\n",
        "        # Standard case\n",
        "        true_positives = len(retrieved_chunks.intersection(true_relevant_docs))\n",
        "\n",
        "        # Precision@k = (True Positives) / (Number of Retrieved Docs)\n",
        "        precision = true_positives / len(retrieved_chunks) if retrieved_chunks else 0.0\n",
        "\n",
        "        # Recall@k = (True Positives) / (Total Number of True Relevant Docs)\n",
        "        recall = true_positives / len(true_relevant_docs) if true_relevant_docs else 0.0\n",
        "\n",
        "        precision_scores.append(precision)\n",
        "        recall_scores.append(recall)\n",
        "\n",
        "    # Calculate mean scores\n",
        "    mean_precision = np.mean(precision_scores)\n",
        "    mean_recall = np.mean(recall_scores)\n",
        "\n",
        "    return {\"precision_at_3\": mean_precision, \"recall_at_3\": mean_recall}\n",
        "\n",
        "# --- 5. Main Execution ---\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize and fit the retriever\n",
        "    retriever = VectorRetriever()\n",
        "    retriever.fit(FINANCIAL_DOCUMENTS)\n",
        "\n",
        "    # Run the evaluation\n",
        "    print(\"Running retrieval evaluation...\")\n",
        "    scores = evaluate_retriever(retriever, TEST_SET, k=3)\n",
        "\n",
        "    # Print the results\n",
        "    print(\"\\n--- Retrieval Evaluation Results ---\")\n",
        "    print(f\"Test Set Size: {len(TEST_SET)} queries\")\n",
        "    print(f\"Retrieval k: 3\\n\")\n",
        "\n",
        "    print(f\"Mean Precision@3: {scores['precision_at_3']:.2%}\")\n",
        "    print(f\"Mean Recall@3:    {scores['recall_at_3']:.2%}\")\n",
        "    print(\"------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyr_bftlVvKB",
        "outputId": "67f7d568-cae7-4f34-ac28-bf7372b71239"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running retrieval evaluation...\n",
            "\n",
            "--- Retrieval Evaluation Results ---\n",
            "Test Set Size: 8 queries\n",
            "Retrieval k: 3\n",
            "\n",
            "Mean Precision@3: 41.67%\n",
            "Mean Recall@3:    68.75%\n",
            "------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}